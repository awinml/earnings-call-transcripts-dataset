

Thomson Reuters StreetEvents Event Transcript
E D I T E D   V E R S I O N

Q2 2017 NVIDIA Corp Earnings Call
AUGUST 11, 2016 / 9:00PM GMT

================================================================================
Corporate Participants
================================================================================

 * Arnab Chanda
   NVIDIA Corporation - VP of IR
 * Jen-Hsun Huang
   NVIDIA Corporation - President & CEO
 * Colette Kress
   NVIDIA Corporation - EVP & CFO

================================================================================
Conference Call Participiants
================================================================================

 * Vijay Rakesh
   Mizuho Securities - Analyst
 * Steve  Smigie
   Raymond James - Analyst
 * Harlan Sur
   JPMorgan - Analyst
 * Blayne Curtis
   Barclays Capital - Analyst
 * C.J. Muse
   Evercore ISI - Analyst
 * Steven Chin
   UBS - Analyst
 * Craig Ellis
   B. Riley & Co. - Analyst
 * Vivek Arya
   BofA Merrill Lynch - Analyst
 * Mitch Steves
   RBC Capital Markets - Analyst
 * Kevin Cassidy
   Stifel Nicolaus - Analyst
 * Matt Ramsay
   Canaccord Genuity - Analyst
 * Joe Moore
   Morgan Stanley - Analyst
 * Rajvindra Gill
   Needham & Company - Analyst
 * Ambrish Srivastava
   BMO Capital Markets - Analyst
 * Mark Lipacis
   Jefferies LLC - Analyst
 * Ross Seymore
   Deutsche Bank - Analyst
 * Romit Shah
   Nomura Securities Co., Ltd. - Analyst
 * Brian Alger
   Raymond James - Analyst
 * Toshi Otani
   TransLink Capital - Analyst
 * Ian Ing
   MKM Partners - Analyst

================================================================================
Presentation
================================================================================
--------------------------------------------------------------------------------
Operator    [1]
--------------------------------------------------------------------------------
Good afternoon. My name is Desiree, and I will be your conference Operator today. I would like to welcome you to the NVIDIA financial results Conference Call. All lines have been placed on mute. After the speakers' remarks, there will be a question-and-answer period. 
(Operator Instructions) 
I will now turn the call over to Arnab Chanda, Vice President of Investor Relations at NVIDIA. You may begin your conference. 

--------------------------------------------------------------------------------
Arnab Chanda,  NVIDIA Corporation - VP of IR    [2]
--------------------------------------------------------------------------------
Thank you. 
Good afternoon, everyone, and welcome to NVIDIA's Conference Call for the Second Quarter of FY17. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer, and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that today's call is being Webcast live on NVIDIA's Investor Relations website. 
It is also being recorded. You can hear a replay by telephone until the 18th of August, 2016. The Webcast will be available for replay up until next quarter's Conference Call to discuss Q3 financial results. 
The content of today's call is NVIDIA's property. It cannot be reproduced or transcribed without our prior written consent. 
During the course of this call, we may make forward-looking statements based on current expectations. These forward-looking statements are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q, and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All of our statements are made as of today, the 11th of August 2016, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. 
During this call, we will discuss non-GAAP financial measures. You can find your reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. 
With that, let me turn the call over to Colette. 

--------------------------------------------------------------------------------
Colette Kress,  NVIDIA Corporation - EVP & CFO    [3]
--------------------------------------------------------------------------------
Thanks, Arnab. 
This quarter, we introduced our new family of Pascal-based GPUs, one of our most successful launches ever. We also benefited from both the winding adoption of deep learning and our expanding engagement with hyperscale data centers around the world as they apply deep learning to all the services they provide. 
Revenue continued to accelerate, rising 24% to a record $1.43 billion. We saw strong sequential and year-on-year growth across our four platforms. Gaming, professional visualization, data center, and automotive. Our business model based on driving GPU compute platforms into highly targeted markets is clearly succeeding. The GPU business was up 25% to $1.2 billion from a year ago.  The Tegra processor business increased 30% to $166 million. 
In Q2, our four platforms contributed nearly 89% of revenue, up from 85% a year earlier and 87% in the preceding quarter. They collectively increased 29% year-over-year. 
Let's begin with our gaming platform. Gaming revenue increased 18% year on year to $781 million reflecting the success of our latest integration of Pascal-based GPUs. Demand was strong in every geographic region. 
The Pascal architecture offers a number of amazing technological advances. It enables unprecedented performance and efficiencies for playing sophisticated AAA gaming titles and driving rich, immersive VR experiences. 
In our most successful launch ever, we introduced four major products. They are GeForce GTX1080, 1070, and 1060 for the enthusiast market and the Titan X, the world's fastest consumer GPU for deep learning development, digital content creation, and extreme gaming. 
Wired magazine called the GTX 1080 an unprecedented piece of electronic precision, one that performs Herculean feats of computational strength. Forbes called GTX1060, which brings a premium VR experience within reach of many, a fantastic product, and Hardware Canucks describes Titan X as a technological tour de force with frame rates that are simply mind-boggling. The GTX 1080, 1070, 1060, and Titan X are now in full production and available to consumers worldwide. 
VR's potential is on vivid display in a new, open source game that we released during the quarter. Available on Steam, NVIDIA VR Funhouse is an open source title created with our GameWorks SDK. It integrates physical simulation into VR along with amazing graphics and precise haptics that you feel like you're actually at a carnival. 
Moving to professional visualization, Quadro revenue grew to a record $214 million, up 22% year on year and up 13% sequentially. Growth came from the high end of the market for realtime rendering tools and mobile workstations. The M6000 GPU 24-gig launched earlier this year is drawing strong interest from a broad range of customers. 
Digital Domain, a leading special effects studio, is using Quadro to accelerate productivity for its work on films and commercials, which requires especially tight turnaround times. Engineering giant AECOM and the Yale school of architecture are using Quadro to accelerate their design and engineering workflows. 
Last month at SIGGRAPH conference, we introduced a series of new products that embed photo-realistic and immersive experience into workflows incorporating Iray a and VR. We launched the Pascal-based Quadro P6000, the most advanced workstation GPU, enabling designers to manipulate complex designs up to twice as fast as before. We demonstrated how deep learning is being brought to the realm of the industrial design to create better products faster.  And, we launched eight new and updated software libraries such as VRWorks 360 video SDK which brings panoramic video to VR. 
Moving to data center, revenue reached a record $151 million, more than doubling year on year and up 6% sequentially. This impressive performance reflects strong growth in supercomputing, hyperscale data centers, and grid virtualization. Interest in deep learning is surging as industries increasingly seek to harness this revolutionary technology. 
Hyperscale companies remain fast adopters of deep learning. Both for training and realtime inference, particularly for natural lingual processing, video, and image analysis. Among them are Facebook, Microsoft, Amazon, Ali Baba, and Bidoo.  Major cloud providers are also offering GPU computing for their customers. Microsoft Azure is now using NVIDIA's GPUs to provide computing and graphics virtualizations. 
During the quarter, we began shipping Tesla P100, the world's most advanced GPU accelerator based on the Pascal architecture. Designed to accelerate deep learning training, it allows application performance to scale up to 8 GPUs using our NV link interconnect. We also announced a variant of P100 based on PCI express that makes it suitable for a wide range of accelerated servers. 
At our GPU Technology Conference in April, we introduced DGX1, the world's first deep learning super computer.  Equipped with eight P100s in a single box, it provides deep learning performance that is equivalent to 250 traditional servers. It comes loaded with NVIDIA software and AI application developers. 
We are seeing strong interest in DGX1 from AR researchers and developers across academia, government labs, and large enterprises. Two days ago, Jen-Hsun hand-delivered the very first DGX1 production model to the open AI institute. They plan to use the system in part to build autonomous agents like chat box, cars, and robots.  Broader deliveries, will commence later this quarter. 
We will be talking more about deep learning later this year at regional versions of our GPU technology conference set for eight cities around the world. Among them Beijing, Amsterdam, Tokyo, and Seoul, as well as Washington DC. 
Our grid graphics virtualization business more than doubled in the quarter. Adoption is accelerating across a variety of industries, particularly automotive and AEC.  Among customers added this quarter was StatOil, a Norwegian Oil & Gas Company. 
Finally, in automotive, revenue increased to a record $119 million, up 68% year-over-year and up 5% sequentially, driven by premium infotainment and digital cockpit features in mainstream cars. Our effort to help partners develop self-driving cars continues to accelerate. We have started to ship our drive PX2 automotive super computer to the 80-plus companies using both our hardware and DRI work software to develop autonomous driving technologies. 
We remain on track to ship our autopilot solution based on the drive platform. Beyond our four platforms, our OEM and [IPA] business was $163 million, down 6% year on year in line with mainstream PC demands. Now, turning to the rest of the Income Statement, we had a record GAAP gross margins of 57.9% while non-GAAP gross margin was 58.1%. These reflect the strength of our GeForce gaming GPUs, the success of our platform approach, and strong demand for deep learning. GAAP operating expenses were $509 million, down 9% from a year earlier. Non-GAAP operating expenses were $448 million, up 6% from a year earlier. This reflects increased hiring in R&D and Marketing expenses, partially offset by lower legal fees. 
GAAP operating income for the Second Quarter was $317 million compared to $76 million a year earlier. Non-GAAP operating income was $382 million, up 65%. Non-GAAP operating margins improved 680 basis points from a year ago to 26.8%. 
Now, turning to the outlook for the third quarter of FY17,we expect revenue to be $1.68 billion, plus or minus 2%. Our GAAP and non-GAAP gross margins are expected to be 57.8% and 58%, respectively, plus or minus 50 basis points. 
GAAP operating expenses are expected to be approximately $530 million. Non-GAAP operating expenses are expected to be approximately $465 million. GAAP and non-GAAP tax rates for the third quarter of FY17 are both expected to be 21%, plus or minus 1%. Further financial details are included in the CFO commentary and other information available on our IR website. 
We will now open the call for questions. Operator, could you please poll for questions? Thank you. 


================================================================================
Questions and Answers
================================================================================
--------------------------------------------------------------------------------
Operator    [1]
--------------------------------------------------------------------------------
(Operator Instructions) 
Your first question comes from the line of Mark Lipacis. 

--------------------------------------------------------------------------------
Mark Lipacis,  Jefferies LLC - Analyst    [2]
--------------------------------------------------------------------------------
Hi. Thanks for taking my questions. First question on the data center business.  Can you all help us understand to what extent is the demand being driven by the deep learning applications versus the classic computationally intense design applications? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [3]
--------------------------------------------------------------------------------
Sure, Mark. Data center -- our data center business is comprised of three basic markets as you're alluding to. One of them is high-performance computing, and one could say that or characterize it as a traditional supercomputing market, very computationally intensive. A second market is grid which is our data center virtualization, basically graphics application virtualization. You could stream and serve any PC or any PC application from data center to any client device.  And, the third application is deep learning, and this is largely hyperscale data centers applying deep learning to enhance their applications to make them much smarter and much more delightful. The vast majority of the growth comes from deep learning by far, and the reason for that is because high performance computing is a relatively stable business. It's still a growing business, and I expect the high-performance computing to do quite well over the coming years. Grid is a fast-growing business.  I think Colette said that it was growing 100% year-over-year, but it's from a much smaller base, and deep learning is not only significant in size, it's also growing quite substantially. 

--------------------------------------------------------------------------------
Mark Lipacis,  Jefferies LLC - Analyst    [4]
--------------------------------------------------------------------------------
That's very helpful, thank you.  And then, last question. On the new -- so, you're just starting to ship Pascal now.  I guess my understanding is that historically as you're shipping a new product, the yields have opportunity for improvement, and the more volume you ship the more you climb down the yield curve. What classically happens to here on the yield?  And, does that positively impact gross margins over the next three or four quarters? Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [5]
--------------------------------------------------------------------------------
Yes, so we've talked extensively about the way we prepare for new process nodes over the last several years. For long-term NVIDIA followers, you might have recalled that 40-nanometer was a very challenging node for us.  And, with all of these challenges, it's an opportunity for us to improve our Company.  We've implemented a very rigorous process node preparation methodology, and it starts, of course, with some of the world's best process engineers, circuit design engineers, and process readiness teams.  We have a fantastic group dedicated to just getting process ready for us.  
And, the second part of it is how that process readiness is integrated throughout the entire Company so I'm really proud of the way that the Company executed on Pascal. 16-nanometer finfet is no trivial task, not to mention the speed of the memories that we use. It's the world's first G5x. We also ramped the world's first HBM2 memory and 3D memory stacking.  So, the number of technological challenges that we overcame in the ramp of Pascal is quite extraordinary.  I'm super-proud of the team. Going forward, we are going to continue to refine yields, and that is absolutely the case. However, we came into 16-nanometer with a great deal of preparedness, and so it's too early to guess what's going to happen to yields and margins long term.  But, we'll guide one quarter at a time. 

--------------------------------------------------------------------------------
Operator    [6]
--------------------------------------------------------------------------------
Your next question comes from the line of Toshi Otani. 

--------------------------------------------------------------------------------
Toshi Otani,  TransLink Capital - Analyst    [7]
--------------------------------------------------------------------------------
Hi.  Thank you for taking my questions and congrats on a very strong quarter. Your Q3 revenue guide implies further acceleration on a year-over-year basis. Are there one or two end markets where you expect outsized growth?  Or, should we expect growth in the quarter to be broad-based? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [8]
--------------------------------------------------------------------------------
Yes, Toshi. I appreciate it. We are experiencing growth in all of our businesses. Our strategy of focusing on deep learning, self-driving cars, gaming, and virtual reality where markets -- these are markets where GPU makes a very significant difference is really paying off.  And, this quarter is really the first quarter where we saw growth across every single one of our businesses, and my expectation is that we're going to see growth across all of our businesses next quarter as well.  But, it's driven by the focus on these key markets and away from traditional commodity components businesses. I think one particular dynamic sticks out, and it's a very significant growth driver where we have an extraordinary position in.  It's deep learning. Deep learning, you may have heard is a  new computing approach. It's a new computing model and requires a new computing architecture, and this is where the parallel approach of GPUs is perfectly suited.  And, five years ago we started to invest in deep learning quite substantially, and we made fundamental changes and enhancements for deep learning across our entire stack of technology from the GPU architecture to the GPU design to the systems that GPUs connect into. For example, NVLink to other systems software that has been designed for it like [Kudi] and [N] and digits to all of the deep learning experts that we have now in our Company. The last five years, we've quietly invested in deep learning because we believe that the future of deep learning is so impactful to the entire software industry, the entire computer industry that we, if you will, pushed it all-in. Now, we find ourselves at the epicenter of this very important dynamic, and it is probably -- if there is one particular growth factor that is of great significance that would be deep learning. 

--------------------------------------------------------------------------------
Operator    [9]
--------------------------------------------------------------------------------
Your next question comes from the line of Vivek Arya. 

--------------------------------------------------------------------------------
Vivek Arya,  BofA Merrill Lynch - Analyst    [10]
--------------------------------------------------------------------------------
Thank you for taking my question, and congratulations on good growth and the execution. Jen-Hsun, the first question is tied to PC gaming, very strong trends. I was curious if you could quantify how much of your base has upgraded to Pascal?  And, have you noticed any change in the behavior of gamers in this upgrade cycle?   Whether it's the price or what part of the stack they are buying now?  And, how quickly they are refreshing versus what you might have seen in the Kepler and the Maxwell cycles?  

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [11]
--------------------------------------------------------------------------------
Sure.  Thanks a lot, Vivek. Let's see, on PC gaming, there's a few dynamics. Our installed base represents somewhere around 80 million active GeForce users around the world.  And, in fact, only about one-third has even upgraded to Maxwell, and we only started shipping Pascal half of this last quarter. And so, that gives you a sense of how much -- and Pascal is unquestionably the biggest leap we've ever made generationally in GPUs ever. It is not only high performance, it is also energy efficient, and it includes some really exciting new graphics technologies for VR and others.  I think Pascal is going to be enormously successful for us, and it comes at a time when the PC gaming marketplace is also quite different than the PC gaming market five years ago. 
One dynamic that's really quite powerful is that the production quality, the production content is much, much higher in video games today than ever.  And, the reason for that -- I've mentioned several times in previous calls -- is that the installed base of capable game platforms that are architecturally compatible, meaning that PlayStation 4 and Xbox 1 and PCs are essentially architecturally compatible.  And so, the footprint for developers has grown tremendously over previous generations. This is a dynamic that's relatively new.  And so, as a result, the quality of games go up which means that the consumption of GPU capability goes up with it.  I think  we're absolutely seeing that dynamic. I'm super-excited about the fact that the Next-Generation game console, the big boost, the 2x boost is coming just around the corner.  That's going to allow game content providers, game developers to aim even higher, and I think that that's going to support long-term expansion of our gross margins and ASPs of PC gaming. 
I would say that there's some other dynamics that are quite powerful as well as you know very well which is eSports is no longer just an interest. E-Sports is a full-force global phenomenon and very powerful in Asia in just about every developing country, and of course, the western world as well.  I think that on top of that, not only is VR off to a great start.  We're seeing some great content now.  But, some of the things that we introduced recently with Pascal, tapping into this grassroots but rather global interest in using video game as an art medium.  We introduced project NVIDIA Ansel which is the world's first in-game photography system.  It allows you to create virtual reality photographs, and it's just really, really amazing.  And so, you could use your video game, capture your amazing moments, share it in VR, or in high resolution with all of your friends.  There's a lot of different ways to enjoy games now, and the production value just continues to go up which is great for our platforms. And so, I think just to summarize your initial question, how much of the installed base has upgraded to Pascal -- very, very small, of course, because we just started production ramp.  But, even then, only one-third has upgraded to Maxwell, and so there's a pretty large, pretty significant upgrade opportunity ahead of us. 

--------------------------------------------------------------------------------
Operator    [12]
--------------------------------------------------------------------------------
Your next question comes from the line of Steven Chin. 

--------------------------------------------------------------------------------
Steven Chin,  UBS - Analyst    [13]
--------------------------------------------------------------------------------
Hi, thanks for taking my questions.  Jen-Hsun, the first one if I could on the data center competitive landscape. Earlier this week, we saw one of your data center competitors make an acquisition of a smaller private Company, and I was wondering if you could talk a little bit more about how you view your position in the data center market with respect to machine learning AI?  And also, how your products are positioned from the high end or low end-type of machine learning application performance?   

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [14]
--------------------------------------------------------------------------------
Sure, thanks. Well, as you can imagine, we have a good pulse on the state of the industry, and we've been in this industry since the very beginning.  Deep learning was really ignited when pioneering researchers around the world discovered the use of GPUs to accelerate deep learning and made a practical -- made it even practical to use deep learning as an approach for developing software. The GPU was a perfect match because the nature of the GPU is a sea of small processors, not one big processor, but a whole bunch of small processors.  And, vitally, they're connected by this connecting tissue.  This connecting tissue inside our processor, connecting memory, connecting fabric.  That makes it possible for the processors to communicate with each other all simultaneously. That architectural innovation has been the source of our GPU computing initiative some 10 years ago. That invention has really been groundbreaking. And so, the GPU was really quite a perfect match for deep learning where neural nets are communicating neurons essentially -- inspired by neurons communicating with each other all simultaneously.  And so, the GPU was really quite a perfect match. 
If you look at deep learning today, five years later, I think that it's a foregone conclusion that deep learning is being infused into just about every single Internet service to make them smarter, more intelligent, more delightful to consumers.  And so, you could see that the hyperscale adoption of deep learning is not only broad, it's large scale and is completely global.  This new computing approach, we realized was going to be quite significant long term and so five years ago we started making quite significant investments across the entire stack of our Company. GPU computing is not just the GPU chip.  It's GPU architecture, it's the GPU design.  It's the GPU system.  All of the algorithms that run on top of it.  All of the tools that run on top of it.  The frameworks -- our collaborations with researchers all over the world.  And so, that collaboration and our investment has improved deep learning on GPUs dramatically in the last two generations when we started this, we were in Kepler.  Maxwell was some 10 times better, and Pascal is some 10 times better than Maxwell.  So, in just two generations, just five years time, we've improved deep learning by an enormous amount, and the GPU today is very unlike a GPU back in the good old days because of all of the work that we've done to it.  
Our strategy -- and this is where we are different not only the focus on the GPU and the expertise in parallel computing, but where we are really different, I would say, is our singular architecture approach to deep learning. We've essentially put all of our investment behind one architecture. We make this architecture available from hyperscale to data centers to workstations to notebooks to PCs, to cars, to embedded computers, to even a brand new, fully integrated, high performance computer in a box we call DGX, the NVIDIA DGX1.  So, there's so many different ways to gain access to the NVIDIA architecture, the NVIDIA platform for deep learning. 
It's just literally all over the place, all around you. It's available to you in retail stores and E-tail stores from OEMs in the cloud or even universities all over the world just in embedded computer kits.  So, our approach is quite singular and quite focused, and my sense is that our lead is quite substantial, and our position is very good.  But, we are not sitting on our laurels as you can tell, and for the last five years, we've been investing quite significantly.  And so, over the next several years, I think you're going to continue to see quite significant jumps from us as we continue to advance in this area. 

--------------------------------------------------------------------------------
Operator    [15]
--------------------------------------------------------------------------------
Your next question comes from the line of Romit Shah. 

--------------------------------------------------------------------------------
Romit Shah,  Nomura Securities Co., Ltd. - Analyst    [16]
--------------------------------------------------------------------------------
Yes, thank you. I had a question on automotive. You mentioned that drive PX is now shipping to 80 car companies. Jen-Hsun, I'm curious, are the wins here similar in size and focused more on prototyping?  Or, are there opportunities here that could ultimately translate into full production wins and drive the automotive business disproportionately? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [17]
--------------------------------------------------------------------------------
Well, I appreciate the question. Yes, we've just started this quarter shipping drive PX2.  Before I answer your question, let me tell you what drive PX2 is. Drive PX2, of course, is a processor. It's the drive PX2 version with just one single processor with just Parker and our Tegra processor.  And, optionally, with discrete GPUs, you could build a car with auto-pilot capability or an AI co-pilot capability all the way to self-driving car capability. And, it was able to do sensor fusion.  It was able to do SLAM, which is localization and mapping.  Detection, using deep neural nets of the environment.  In a surround matter, all of the cameras around the car, all feeding into the processor.  And, the drive PX processor doing realtime inferencing of surround cameras.  All the way to the actual planning and driving of the car -- all done in this one car computer, this one car AI super computer. 
And so, this quarter, we started them shipping to all of our partners and developers so that they can start developing their software and their systems around our computer and on top of our software stack. We have the intentions of shipping in volume production many of these, and it's hard to know exactly what everybody's schedule is.  But, it ranges everything from very soon to the next couple of years. And, developing a self-driving car is no -- it's a fairly significant undertaking.  Nobody does it for fun surely, and the question is maybe if I could frame the question just slightly differently, do I expect people to be building OEM cars? Or, do we expect them to be building shuttles that are maybe geofenced? Do we expect them to be building trucks? And, you know how many trucks are on the road and how much of the world's economy is built around trucking products all over the world to services of basically taxi as a service. The answer is that we're working with customers and partners across that entire range from cars that are sold to trucks to vans to shuttles to services. 

--------------------------------------------------------------------------------
Operator    [18]
--------------------------------------------------------------------------------
Your next question comes from the line of Craig Ellis. 

--------------------------------------------------------------------------------
Craig Ellis,  B. Riley & Co. - Analyst    [19]
--------------------------------------------------------------------------------
Yes, thanks for taking the question. The first is just a follow-up on some of the gaming strength in the quarter with the Company launching the Founders addition availability of gaming products in the quarter.  Can you talk about how that went?  And, for those products, how gross margins compare to just chip bait sales that would go into a gaming card OEM?   

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [20]
--------------------------------------------------------------------------------
Well, first of all Founders edition -- I appreciate you asking that. Founders edition is engineered by NVIDIA, completely built by NVIDIA, and sold directly by NVIDIA and supported by NVIDIA. There's some people that -- some gamers and customers who would prefer to have a direct relationship with our Company. It's availability is limited, and it's engineered just at the highest possible level of quality.  And, we limit the production of it. The reason for that is because we have a network of partners who are much, much more able to take the NVIDIA architecture to every corner of the world literally overnight. We have a fair number of partners who blanket every single country on the planet as we know, and they can provide them in different sizes and shapes and styles and different thermal solutions and different configurations and different price points.  I think we believe that that diversity is one of the reasons why the NVIDIA GeForce platform is so popular, and it creates a lot of excitement in the marketplace and a lot of interesting and different diversified designs. So, I think those two strategies are harmonious with each other.  But, the key point is we built the Founders edition really as a way for some customers to be able to purchase directly and have a relationship directly with us.  But, largely, our strategy is to go to the market with a network of partners. As for gross margins, [the margins are the same]. 

--------------------------------------------------------------------------------
Operator    [21]
--------------------------------------------------------------------------------
Your next question comes from the line of Matt Ramsay. 

--------------------------------------------------------------------------------
Matt Ramsay,  Canaccord Genuity - Analyst    [22]
--------------------------------------------------------------------------------
Yes, good afternoon. Thank you. Jen-Hsun, I wanted to ask a couple questions again on the data center business. The first being, we've done a little bit of work trying to estimate in our team what the long-term server attach rate for accelerators in general could be and for GPUs within that.  So, it would be really interesting to hear your perspectives on that?  And then, secondly, is there a market there for an APU-type product in the data center? I know you have project Denver and some other things going on from the CPU perspective, but is there a deep learning integrated CPU/GPU play that might open up more TAM long term for your Company that you are considering pursuing?  Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [23]
--------------------------------------------------------------------------------
Sure. Yes, first of all, the type of work loads in the data center has really changed. Back in the good old days, it largely ran database searches, but that has changed so much. It's no longer just about text. It's no longer just about data. The vast majority of what's going through the internet and what's going through data centers today as you know very well are images.  They are voice.  They are increasingly and probably one of the most important new data formats is live video. 
Live video, if you think about it for just a moment, it's live video.  So, it doesn't stay in the server, and it doesn't get recorded which means that if you want to enjoy that live video there needs to be a fair amount of artificial intelligence capability in the data center that's running realtime on their live video so that the person that might be interested the video stream that you're streaming knows who to alert and who to invite to come and watch the live video.  And so, if you think about data center traffic going forward, my sense is that the workload is going to continue to be increasingly high throughput, increasingly high multimedia content, and increasingly, of course, powered by AI and powered by deep learning.  And so, I think that's number one. 
The second is that the architecture of the data center is recognizably, understandably changing because the workload is changing. Deep learning is a very different workload than the workload of the past, and so the architecture -- it's a new computing model.  It recognized it needs a new computing architecture, and accelerators like GPUs are really well -- a good fit. So, now the other question is how much. It's hard to say. It's hard to say how much.  But, my sense is that it going to be alive, and without any predictions, it's going to be a lot more than we currently ship.  I think the growth opportunity for deep learning is quite significant. I think every hyperscale data center will be GPU-accelerated. It will be GPU-accelerated for training and GPU-accelerated for inferencing.  There may be other approaches, but I think using GPUs is going to be a very large part of that.  
And then, lastly, APUs. I guess my sense is for data centers, energy efficiency is such a vital part and although the work load is increasingly AI and increasingly live video and multimedia where GPUs can add a lot of value. There's still a lot of workload that is CPU-centric, and you still want to have an extraordinary CPU.  I don't think anybody would argue that Intel makes the world's best CPUs. It's not even close.  There's not even a close second, and so I think the artfulness of and the craftsman ship of Intel CPUs is pretty hard to deny.  For most data centers, if you have CPU workloads anyway, I think Intel's Xeons are hard to beat, and so that's my opinion anyway. 

--------------------------------------------------------------------------------
Operator    [24]
--------------------------------------------------------------------------------
Your next question comes from the line of Ian Ing. 

--------------------------------------------------------------------------------
Ian Ing,  MKM Partners - Analyst    [25]
--------------------------------------------------------------------------------
Yes, thank you. Earlier you talked about taping out all of the Pascal products at this point. Are you with three products in the market, are you ceding the sub-$250 price point for cards to competition?  Or, is this something you can serve with older Maxwell product or some upcoming product? Thanks. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [26]
--------------------------------------------------------------------------------
Thanks a lot, Ian. We have taped out.  We have verified.  We have ramped every Pascal GPU.  That's right.   However, we have not introduced every one. 

--------------------------------------------------------------------------------
Operator    [27]
--------------------------------------------------------------------------------
Your next question comes from the line of Steve Smigie. 

--------------------------------------------------------------------------------
Steve  Smigie,  Raymond James - Analyst    [28]
--------------------------------------------------------------------------------
Great, thanks a lot for the question. I just wanted to follow up a little bit on virtual reality.   You had talked a little bit about investments there.  I was just curious what reception you're getting at this point, and what's going to be in your mind the biggest driver getting that going?  Is it more headsets?  Or, more developers working on that?  Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [29]
--------------------------------------------------------------------------------
Yes, Steve. I think it's all of that. We have to keep pushing VR and get the head mounts out to the world. I think ACC Vive -- they're doing a great job.  Oculus is doing a great job.  We track very carefully all of the head mounts that are going out there, and it's growing all time. Second, the content is really cool and people are really enjoying it.  And so, we've just got to get more content, and developers all over the world are jumping on to VR. It really is a great new experience.  But, it's not just games as you know. One of the areas where we have a lot of success, and we see a lot of excitement is in enterprise and industrial design, in medicine, medical imaging, and architectural engineering. 
We use it ourselves. We are doing a fair amount of design of our workspace, and we render everything using our photo realistic renderer called Iray, fully accelerated by our GPUs.  And then, we render it into VR, and we enjoy it, enjoy it completely in VR.  And, it's something else to be inside an environment that's photo-realistic to be rendered and completely enjoying in VR.  So, architectural engineering and construction is going to benefit from that. So, we see a lot of broad-based adoption of VR. 
Now, one of the things that we did which was really spectacular is the multi-resolution, multi-projection renderings of Pascal. It's the world's first GPU architecture that has the ability to render into multiple projections simultaneously instead of just one, and the reason for that is because the GPU back in the good old days was designed for displaying into one display. You have one keyboard.  You have one display.  But, that mode of computer graphics has really changed as we moved into the world of virtual reality and all kinds of interesting different display configurations and display types.  And so, multi-projection was a revolutionary approach to graphics, and Pascal introduced it.  You really benefit in VR.  
The second thing that we did was we integrated physics -- real world physics simulation into VR. The benefit is that without the laws of physics, as you know, you can't feel anything. Things don't collide. Things don't bounce. When you pick up something, you don't feel the haptics of it. We made the entire environment physically simulated,  and so as a result, you feel the entire environment.  When you tip a bottle of water over, it behaves like a bottle of water tipped over.  Balls behave the way balls behave, and things don't merge into each other.  That integration with haptics has completely revolutionized VR, we believe, and that's physics simulation is another thing. And so, I think our position in VR is really quite great, and I'm super-enthusiastic about the development of VR. 

--------------------------------------------------------------------------------
Operator    [30]
--------------------------------------------------------------------------------
Your next question comes from the line of Vijay Rakesh. 

--------------------------------------------------------------------------------
Vijay Rakesh,  Mizuho Securities - Analyst    [31]
--------------------------------------------------------------------------------
Hi.  Just on the data center side.  Jen-Hsun, you mentioned three key segments, HBC, grid, and deep learning. What percent of mix are those for the data center? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [32]
--------------------------------------------------------------------------------
I would say it's about 50% deep learning at the moment, and probably, call it, 35% -- one third is high performance computing.  Maybe more than that.  And, the rest of it is virtualization.  Going forward, which is part of your question, my sense is that deep learning would become a very significant part of that. The other thing to realize is that deep learning is not just for internet Service Providers for voice recognition and image recognition and face recognition and such. Deep learning is a way of using mathematics, using software to discover insight in a huge amount of data. And, the one place where we generate a huge amount of data is high-performance computing. Every single super computing center in the world is going to be moving towards deep learning, and the reason for that is because they generate a huge amount of data that they really have very little ability to comb through -- to sort through.  And now, with deep learning, they could discover really, really subtle insights in data that is hyper-dimensional.  That's the way to think about deep learning is it's really mathematics.  It's a new form of mathematics that is very, very powerful.  It's a new approach to software.  But, don't think of it as a market. I think every market is going to be a deep learning market. Every application is going to be a deep learning application, and every piece of software will be infused by AI long term. 

--------------------------------------------------------------------------------
Operator    [33]
--------------------------------------------------------------------------------
Your next question comes from the line of Harlan Sur. 

--------------------------------------------------------------------------------
Harlan Sur,  JPMorgan - Analyst    [34]
--------------------------------------------------------------------------------
Good afternoon. Solid job on the quarterly execution. You guys had really good growth in professional visualization, record revenues. I would have thought that most of the growth was being driven by the upcoming release of the Pascal based P5000 and P6000 family.  So I was sort pleasantly surprised that most of the demand was driven by your current generation M6000 family, which means obviously that the Pascal demand cycle is still ahead of you. Number one, is that a fair view?  And then what's driving the strong adoption of M6000, and if you haven't already released it, when do you expect to launch the Pascal-based 5000 and 6000 family?  Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [35]
--------------------------------------------------------------------------------
Yes.  Thanks, Harlan.  I appreciate the question. The team's been working really hard over the years to really change the way that computer aided design is done. Your observation is absolutely right, and it's coming from several different places. First of all, more and more of design is really about product design, industrial design, where the feeling of the product, the aesthetics of the product is just as important as the mechanical design of the product.  And whether you're talking about a building or just a consumer product or a car, we need to be able to simulate the aesthetics of it in a photo realistic way, using real material simulations. The computational load necessary to do that is just really quite extraordinary.  And we're now seeing one design package after another, whether it's [DeSo's] leading packages, Solid Work's leading packages, AutoDesk, Adobe the amount of GPU use has really, really increased and it's increasing quite dramatically. 
I think partly because, finally for all of the ISVs, of all the developers, not only is the market demand for earlier views of photo realistic designs an important decision criteria. They can also rely on the fact that great GPUs are available in just about every computer.  And so the pervasiveness of GPUs allows them to take advantage of the GPUs and to really trust that the software capabilities that they put into their packages, if they rely on GPUs, will have the benefits of GPUs there.  
And so I think that's the virtual cycle you're starting to see in design.  And so the investment that we made in the photo realistic renderings several years ago, the GPU acceleration of optics, this layer for path tracing that is used by just about every software package in the world, our continued evangelism of GPUs and its general purpose use, from computer graphics all the way to imaging, is something that I think is starting to see benefits. That's number one. 
Number two, Maxwell was the most energy efficient GPU ever made, until {Pascal. Maxwell was twice the energy efficiency of Kepler, and the amazing thing is that Pascal is twice the energy efficiency of Maxwell. But Maxwell made it possible for cinema-like designs in laptops and more elegant workstations and the ability to put more horsepower, more capability into any workstation because of power concerns. Maxwell made it possible for the entire industry to uplift the level of GPU that it uses.  
And I think that going forward, your last question is going forward, do we see -- how do we see Pascal? Pascal is in the process of ramping into workstations all over the world.  And so I think in the coming quarters, we're going to expect to see Pascal out there.  And my expectation is that the dynamics that I just described, which is software developers using more photo realistic capabilities, our inventioning of GPU accelerated photo rendering, I-ray and optics and NDL material description language, and then lastly, the energy efficiency of GPUs, those three factors combined is going to be  really helpful for workstations, and then last, VR. VR is coming, and in order to really enjoy these type of applications for design, you're going to need a pretty powerful GPU at this point. 

--------------------------------------------------------------------------------
Operator    [36]
--------------------------------------------------------------------------------
Your next question comes from the line of Ross Seymore. 

--------------------------------------------------------------------------------
Ross Seymore,  Deutsche Bank - Analyst    [37]
--------------------------------------------------------------------------------
Hi, guys.  Thanks for letting me ask a question.  A couple for you, Jen-Hsun, on the automotive side. I guess the first part would be, we've seen in the recent months some partnerships being formed with some of your competitors and some of your customers, and we've seen some of those partnerships actually dissolve.   So how does NVIDIA play in this general ecosystem in forming partnerships or not?  And then the second part, if we put even just a rough year on it, when would you think the autonomous driving part of your automotive business would actually exceed the infotainment size of your automotive business? Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [38]
--------------------------------------------------------------------------------
Yes, thanks a lot, Ross. Well, we play in a graceful, friendly and open way.  And I mean that rather seriously. We believe this. We believe that building an autonomous self-driving car is a pile of software and it's really complicated software. It's really, really complicated software and it's not like one company is going to do it. And it's also not logical that large, great companies who are refining their algorithms and the capabilities of their self-driving cars over the course of the next two decades can outsource to someone the self-driving car stack. We've always felt that self-driving cars is a software problem and that large companies need to be able to own their own destiny.  And that's the reason why PX2 is an open stack.  And it's an open platform.  So that every car company can build their self-driving car on top of it. Number one.  
Number two, the DRIVE PX2 architecture is scalable.  And the reason for that is because automatic braking and auto pilot on a highway and a virtual co-pilot and a completely autonomous self-driving car, a self-driving truck, a geofenced autonomous shuttle, all of these, a completely autonomous taxi, all of these platforms cannot be solved by one chip. It's just not even logical. The computation necessary to do it is so diverse. The more digits of accuracy or the more digits of precision towards safety that you would like to have in dealing with all of the unexpected circumstances, the more nines you would like to have, if you will, the more computation you have to do. Just as voice recognition, the amount of computation necessary for voice recognition over the last just four or five years has increased by 100 times.  But notice how precise and how accurate voice recognition has become.  And image recognition, video circumstance recognition, context recognition, all of that is going to require just an enormous amount of computation.  So we believe that scalable platforms is necessary, number two.  
And then number three. Detection, computer vision and detection, object detection, is just one tiny sliver of the entire autonomous driving problem. It's just one tiny sliver.  And we've always said that autonomous vehicles, self-driving cars, is really a AI computing problem. It's a computing problem because the processors needs not just detection, but also computation, the CPU matters, the GPU matters, the entire system architecture matters, and so the entire computation engine matters. 
Number two computation is -- computing is not just a chip problem. It's largely a software problem. And the body of software necessary for the entire system software stack, if you would, the operating system of a self-driving realtime computer, realtime super computer doesn't exist. Most super computers are best effort super computers. They run a job as fast as they can until they're done. But that's not good enough for self-driving cars. This super computer has to run in real time and it has to react at the moment that it sees that there's danger in the way, and best effort doesn't cut it. You need it to be a real time super computer.  And the world has never built a real time super computer before and that's what DRIVE PX2 is all about, a real time super computer for some round, autonomous AI.  
And so that's the focus that we have. That's the direction that we've taken.  And I think what you're seeing is that the market is starting to react to that. That maybe as they go further and further into autonomous driving, that they're discovering that the problems are related to the type of problems that we're seeing and that's the reason why DRIVE PX is a computer, not a smart camera. 

--------------------------------------------------------------------------------
Operator    [39]
--------------------------------------------------------------------------------
And your next question comes from the line of Joseph Moore. 

--------------------------------------------------------------------------------
Joe Moore,  Morgan Stanley - Analyst    [40]
--------------------------------------------------------------------------------
Great.  Thank you so much. You talk about deep learning in the hyperscale environment, but it seems like you're getting some traction as well in the enterprise environment.  I know at least one IT department that we've talked to has been doing some implementation. Can you talk about your progress there and what does it take for you to build that presence within more traditional enterprises? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [41]
--------------------------------------------------------------------------------
Well, as you know, deep learning is not just a internet service approach. Deep learning is really machine learning super charged. And deep learning is really about discovering insight in big data, in big unstructured data, in multi-dimensional data.  And that's what deep learning, that's what I've called it Thor's hammer that fell from the sky.  And it's amazing technology that these researchers discovered.  And we were incredibly, incredibly well prepared, because GPUs is naturally parallel. And we put us in a position to really be able to contribute to this new computing revolution. 
But when you think about it in the context that it's just, it's software development, it's a new method of doing software and it's a new way of discovering insight from data, what company wouldn't need it? So every medical, every life sciences company needs it. Every health care company needs it. Every energy discovery company needs it. Every E-tail, retail company needs it. Everybody has lots of data. Everybody has lots and lots of data that they own themselves. Every manufacturing company needs it. Every company that cares about security, every company that deals with a massive amount of customer data has the benefit, can benefit from deep learning.  And so when you frame it in that context, I think I would say that deep learning's market opportunity is even greater in enterprises than it is in consumer internet services.  
And that's exactly the reason why we built the NVIDIA DTX1.  Because most of these Enterprises don't have the expertise or simply don't have the willpower to want to build a super computing data center or a high performance computer. They would rather buy an appliance, if you will, with all of the software integrated and the performance incredibly well tuned, and it comes out of a box.  And that's essentially what NVIDIA DGX1 is.  It's a super computer in a box and  it's designed and tuned for high performance computing for deep learning. 

--------------------------------------------------------------------------------
Operator    [42]
--------------------------------------------------------------------------------
Your next question comes from the line of Ambrish Srivastava. 

--------------------------------------------------------------------------------
Ambrish Srivastava,  BMO Capital Markets - Analyst    [43]
--------------------------------------------------------------------------------
Hello.  Thank you very much for squeezing me in. I had one question on gross margin, Jen-Hsun. Very big top line guidance, but yet gross margin is guided to flat. What is the reason?  And I understand it's not always perfectly correlated, margins should be going up that much, but is it pricing, is it yield? Because the mix also seems to be moving in the right direction, more [Pro Ves], more HPC and less of the OEM business. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [44]
--------------------------------------------------------------------------------
Well, our guidance is our best estimate.  And we'll know how everything turns out next quarter when we talk again.  But at some high level, I would agree with you that as we move further and further and more and more into our platform approach of business, where our platform is specialized and rich with software, that increasingly the value of the product that we bring has extraordinary enterprise value, that the benefits of using it is not just measured in frames per second but real TCO for companies and real cost savings as they reduce the number of server clusters, and real increases and real boosts in their productivity.  And so I think there's every reason to believe that long term, this platform approach can drive greater value.  But as for the next quarter, I think let's just wait and see how it goes. 

--------------------------------------------------------------------------------
Operator    [45]
--------------------------------------------------------------------------------
Your next question comes from the line of Rajvindra Gill. 

--------------------------------------------------------------------------------
Rajvindra Gill,  Needham & Company - Analyst    [46]
--------------------------------------------------------------------------------
Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [47]
--------------------------------------------------------------------------------
It's Vindra.  How are you? 

--------------------------------------------------------------------------------
Rajvindra Gill,  Needham & Company - Analyst    [48]
--------------------------------------------------------------------------------
Exactly. Good. A question, Jen-Hsun, on the DRIVE PX2. So my understanding, as you described it, it's one scalable architecture from the cockpit to ADAS to mapping to autonomous driving.  But I'm curious to see how that compares to the approach that some of your competitors are taking with respect to providing different solutions for different levels of the ADAS systems, whether it's level one, level two, level three, specifically with the V2x communication where, for level four autonomous driving, where you're going to need 6 to 20 different radar units, 3 to 6 different cameras, [lidar].  I'm trying to square how your approach is different from some of your competitors in the semiconductor space. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [49]
--------------------------------------------------------------------------------
Yes, good question. There's no way to square and there's no reason to square, and you aren't going to find one answer.  And the reason why you aren't going to find one answer is because nobody knows exactly how to get it done. We all have intuitions and we all have beliefs about how we're going to be able to ultimately solve the long-term fully autonomous vehicle, that wherever I am, the car I step into, the automotive automobile we step into, is completely autonomous, and that it has AI inside and out, and it's just an incredible experience.  But we aren't there yet.  
And all of these companies have slightly -- not all -- but many companies have slightly different visions of the future. Some people believe that the path to the future is fully autonomous right away in a geofenced area that has been fully mapped in advance. Some people believe that you can use it just for highway auto pilot as a first starting point and work quickly towards fully autonomy, and some people believe the best way to do that is through shuttles and trucks.  So you see a lot of different visions out there.  And I think all of those visions are coming from smart people doing smart things and they're targeting different aspects of transportation. 
I think there's a fallacy that transportation in every single country in every single form is exactly the same. It just doesn't work that way.  And so there's technology insight and then there's market insight, and there's a technology vision versus your entry point.  And I think that's where all of the squaring doesn't happen. So you're solving for a simple equation that won't happen.  However there's one thing that we believe absolutely will happen. We are absolutely certain that AI will be involved in this endeavor, that finally with deep learning and finally with AI that we believe we have the secret sauce necessary to break these puzzles and to solve these puzzles over a period of time.  Number one.  
Number two.  We believe unquestionably that depending on the problem you want to solve, you need a different amount of computational capability. We believe unambiguously this is a software problem, and that for the largest of transportation companies, they need to own their own software in collaboration with you, but they aren't going to let you do it and keep it as a black box. We believe unambiguously that this is a computing problem, that this is a real time super computing problem., that it's not just about a special widget, but computation is necessary, processors, a computer system, systems software, and an enormous amount of operating system capability is necessary to build something like this. 
It is a massive software problem.  Otherwise, we would have done it already.  And so I think you'll see this year the beginnings of a lot of some very visionary and really quite exciting introductions.  But in the next year and the year after that, I think you'll see more and more and more.  I think this is the beginning and we're working with some really, really amazing people to get this done. 

--------------------------------------------------------------------------------
Operator    [50]
--------------------------------------------------------------------------------
Your next question comes from the line of Mitch Steves. 

--------------------------------------------------------------------------------
Mitch Steves,  RBC Capital Markets - Analyst    [51]
--------------------------------------------------------------------------------
Thanks for taking my question, guys.   So just circling back to the data center piece and the deep learning aspect, is there a change in ASPs you guys are seeing when you enter that market? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [52]
--------------------------------------------------------------------------------
No. 

--------------------------------------------------------------------------------
Mitch Steves,  RBC Capital Markets - Analyst    [53]
--------------------------------------------------------------------------------
So essentially there's going to be no margin change from the data center sales.  And I guess the same question in automotive, as well. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [54]
--------------------------------------------------------------------------------
Oh, automotive ASPs for self-driving cars will be much higher than infotainment. It's a much tougher problem. Every car in the world has infotainment. With the exception of some pioneering work or early, the best, the most leading edge cars today, almost no cars are self-driving.  So I think that the technology necessary for self-driving cars is much, much more complicated than lane keeping or adaptive cruise control or first generation, first and second generation ADAS. The problem is much, much more complicated. 

--------------------------------------------------------------------------------
Operator    [55]
--------------------------------------------------------------------------------
Your next question comes from the line of Brian Alger. 

--------------------------------------------------------------------------------
Brian Alger,  Raymond James - Analyst    [56]
--------------------------------------------------------------------------------
Hi, guys. Thanks for squeezing me in. I think this will be the first, congrats, actually, on a pretty darn good quarter and amazing guidance. I want to come back to the difference of Pascal versus what would be otherwise competition from either Intel or AMD. There's been a fair amount of documentation talking about the power requirements or the power draw differences between Pascal versus Polaris.  And one would think that while that's important in gaming and it's gotten a lot of notice, it would actually be more important for these deep learning applications that we've been talking so much about over the past half hour, 45 minutes.  Can you maybe talk to that side of the design, not so much the horsepower, but maybe the power efficiency of it and what that means for when you scale it up into really big problems? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [57]
--------------------------------------------------------------------------------
Brian, thank you very much.  First of all, I appreciate your comment. The team worked really, really hard.  And over the last several years, the last five years, all of the employees of NVIDIA have been pursuing a strategy that took until today, really, to show people that it really pays off and it's a very unique business model. It's a very unique approach. But I just want to congratulate all of the employees that have worked so hard to get us here. 
I appreciate the comment also about energy efficiency. In fact, energy efficiency is the single most important feature of processors today and going forward. And the reason for that is because every single environment that we're in is power constrained, every single environment. Even your PC, with 750 watts or 1,000 watts, is power constrained.  Because we could surely put more GPUs in there than 1,000 watts.  And so that's power constrained.  We're in environments where we only have one or two watts. It might be a drone and we need to be, we're completely power constrained, so energy efficiency is really, really important. We might be in a data center where we're doing deep learning and training we're training neuronets or we're inferencing neuronets.  And in this particular case, although the data center has a lot of power to provision, the number of GPUs that they want to use in it is measured in tens, tens and tens of thousands.  And so energy efficiency becomes the predominant issue. Energy efficiency, literally, is the most important feature of the processor. 
Now from there, from there, there are functionality and architectural features, that the architectural changes that we made in Pascal so that we could stay ahead of the deep learning research work and the deep learning progress, was groundbreaking and people are starting to discover the architectural changes that we put into Pascal and it's going to make a huge difference in the next several years of deep learning.  And so that's a feature and an architectural innovation. 
And then lastly, of course, there's all of the software that goes on top of the processor base. We call it GPU computing instead of just GPUs, because GPU computing is about computing, it's about software, it's systems, it's about the inner relationship of our GPU with the memories and all of the memories around the system and the networking and the inter connect and storage, and it's a large scale computing problem. It is also the highest throughput computing problem on the planet, which is the reason why we've been called upon by our nation to build the world's next two fastest super computers. High throughput computing is our company's expertise. High throughput computing from fundamental architecture to chip design to system design to system software to algorithms to computational mathematics, and all of the experts in all the various fields of science, that is the great investment that we made in the last five years.  And I think the results are really starting to show. 

--------------------------------------------------------------------------------
Operator    [58]
--------------------------------------------------------------------------------
Your next question comes from the line of Blayne Curtis. 

--------------------------------------------------------------------------------
Blayne Curtis,  Barclays Capital - Analyst    [59]
--------------------------------------------------------------------------------
Hey, guys.  Thanks for squeezing me in here and great execution on the quarter. Two related questions. One, Colette, just curious your view on the use of capital and buybacks.  Obviously, an accelerated one, only $9 million in the last quarter.  What's your view going forward?  
And then Jen-Hsun, maybe a bigger question in terms of ease of capital, whether you could talk about, you said CPU is not an area that you would want to go into, but obviously GPUs have legs.  So just curious, if you look around other areas, maybe in the data center, where you could also add value?  

--------------------------------------------------------------------------------
Colette Kress,  NVIDIA Corporation - EVP & CFO    [60]
--------------------------------------------------------------------------------
Yes, thanks, Blayne. The return of capital continues to be an important part of our shareholder value message  But remember, it is still two parts of it. Part of it is still dividends and part of it has been our purchasing of stock. So as we continue to go forward, the dividend is definitely a long term perspective and we'll make sure that we can watch the dividend yield there to stay competitive and also looking at our profitability. Our share repurchase, we'll look at the opportunistic time for those repurchases and making sure that we're also doing that carefully, as well. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [61]
--------------------------------------------------------------------------------
And long-term use of capital, I would say this, that what NVIDIA is really rich with is we're rich with vision and creativity and the courage to innovate.  And that's one of the reasons why we start almost every conversation with anything by gathering our great people around the Company and seeing what kind of future we can invent for ourselves and for the world.  And so I think our use of capital is nurturing the employees that we have and providing them the platform to innovate and create the conditions by which they can be successful and do their live's work.  And so that's philosophically where we start. 
We aren't allergic to acquisitions and purchases, and we look all the time and we have the benefit of working with and partnering with companies large and small all over the world as we move the industry forward.  So we're surely open to that.  But our natural posture is always to invest in our people and invest in our own company's ability to invent the future. 

--------------------------------------------------------------------------------
Operator    [62]
--------------------------------------------------------------------------------
Your next question comes from the line of C.J. Muse. 

--------------------------------------------------------------------------------
C.J. Muse,  Evercore ISI - Analyst    [63]
--------------------------------------------------------------------------------
Good afternoon. Thank you for squeezing me in. I guess, two quick questions.  The first one, thank you for breaking out deep learning as a percentage of the data center. Can you provide what that percentage was for the April quarter?  And then the follow-up question is if I look back over the last four quarters and I look at your implied guide, you're looking at roughly 50%  incremental operating margin. And curious if that's the right number you would underwrite here, or should we be thinking about improving mix, as well as maturing process and manufacturing at your foundry partners such that that could actually be higher as we look ahead?  Thank you. 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [64]
--------------------------------------------------------------------------------
Yes, deep learning is a software approach, a new computing architecture, a new computing approach that the industry, that researchers have been developing for 20 years.  And it was only until five years ago when pioneer work was done on deep learning and on GPUs that really turbo charged it and gave the industry, if you will, a time machine that brought the future to the present.  And the power of deep learning is so great that this capability is expanding and people are discovering more ways to use it and more applications and new deep learning architectures, and the networks are getting bigger and deeper and more complicated.  And so I think that this area, this area is going to grow quite significantly. It represents a vast majority of our data center revenues recently, and my sense is that it's going to continue to be a significant part of it. 
So what was the second question?  Did I miss it? I think his question was really about data centers and deep learning, right? What's that? 

--------------------------------------------------------------------------------
Colette Kress,  NVIDIA Corporation - EVP & CFO    [65]
--------------------------------------------------------------------------------
I think your question was regarding deep learning and the percentage of data center and how that has moved. 

--------------------------------------------------------------------------------
C.J. Muse,  Evercore ISI - Analyst    [66]
--------------------------------------------------------------------------------
Yes, and it's the vast majority. 

--------------------------------------------------------------------------------
Operator    [67]
--------------------------------------------------------------------------------
And your next question comes from the line of Kevin Cassidy. 

--------------------------------------------------------------------------------
Kevin Cassidy,  Stifel Nicolaus - Analyst    [68]
--------------------------------------------------------------------------------
Thanks for taking my question. Maybe I'll go to the other end of the spectrum and speaking of energy efficiency. Are you finding new opportunities for Tegra, aside from the infotainment in automotive? 

--------------------------------------------------------------------------------
Jen-Hsun Huang,  NVIDIA Corporation - President & CEO    [69]
--------------------------------------------------------------------------------
Kevin, I appreciate the question. Tegra is at the core of all of our self-driving car initiatives. And so without Tegra, there would be no self-driving cars. So Tegra is the core of our self-driving car initiative, the computing platform for self-driving cars.  And DRIVE PX2 includes Tegra, as well as discrete GPUs of Pascal, but the core of it, the vast majority of the heavy lifting is done by Tegra, and we expect that going forward.  And so Tegra is incredibly important to us. 
Tegra is also the core of the processor of Jetson. Jetson is a platform that is designed for other embedded autonomous and intelligent machines.  And so you could imagine what kind of intelligent machines in the future will benefit from deep learning and AI, but robotics and drones and embedded applications inside buildings and cities.  There are all kinds of applications. I'm very, very optimistic about the future of Jetson, but at the core of that is also Tegra.  So think of Tegra as our computer on a chip, and it's our AI computer on a chip. 
Okay, may I -- I appreciate all the questions. Thank you all for joining us today. Our growth is really driven by several factors. Our focus on deep learning, self-driving cars, gaming, and VR, markets where GPU has been vital, is really starting to pay off. The second factor is that Pascal is the most advanced GPU ever created and we're incredibly excited about it. And we, this last quarter, we ramped it with enormous success.  And I'm so proud of the team for all of the preparation and the executions last quarter.  And the third is hyper scale adoption of deep learning is now widespread, is large scale and we're seeing it globally. Those are the several growth drivers ahead of us. 
As we go forward, we're also looking to sharing our many developments in deep learning AI with you. We're really just in the beginning of seeing  the actual growth of deep learning as we scale out into the market. Deep learning adoption is now widespread and is ramping at every hyper scale data center. It's a new computing model that requires a new computing architecture, one that GPU is perfectly suited for.  And the thing that we've done that I'm really delighted with is the strategy that started five years ago to optimize our GPU computing platform from end-to-end and optimize it for deep learning, at the processor level, at the architecture level, at the chip design level, systems and software and algorithms and a richness of deep learning experts at the Company, and the collaboration we have all over the world with researchers and developers has made it possible for us to continue to advance this field and this platform.  
And as a result of that our deep learning platform improved far more than anybody would have expected.  If you just projected it based on semiconductor physics, it would be nowhere near the level of speed up and step up that we got from generation to generation, from Kepler to Maxwell, we got 10x, from Maxwell to Pascal, we got another 10x.  And you can surely expect pretty substantial improvements and increases from us over the next several years. 
Where we really shine is not only as a fantastic platform for deep learning and the training of the networks, but it's also a fantastic platform to scale out. You can enjoy our platform, whether it's in cloud or in data center or in super computers and workstations and desk side PCs and notebook computers to cars to embedded computers, as I mentioned just now with Jetson. This is a one singular architecture approach, so the thoughtfulness and the care of the investment of the developers and the software programmers and researchers is really our preeminent concern.  And as we know, computing is about architecture and computing is about platform, and mostly, computing is about developers.  And we've been quite thoughtful about the importance it is to developers.  And as a result, developers all over the world, all over the industry, can use this singular architecture and get the benefits of their science and their applications as they scale and deploy their work. 
So that's it. We had a great quarter and I look forward to reporting our progress next quarter. Thank you all for joining us. 

--------------------------------------------------------------------------------
Operator    [70]
--------------------------------------------------------------------------------
This concludes today's conference call. You may now disconnect. 







--------------------------------------------------------------------------------
Definitions
--------------------------------------------------------------------------------
PRELIMINARY TRANSCRIPT: "Preliminary Transcript" indicates that the 
Transcript has been published in near real-time by an experienced 
professional transcriber.  While the Preliminary Transcript is highly 
accurate, it has not been edited to ensure the entire transcription 
represents a verbatim report of the call.

EDITED TRANSCRIPT: "Edited Transcript" indicates that a team of professional 
editors have listened to the event a second time to confirm that the 
content of the call has been transcribed accurately and in full.

--------------------------------------------------------------------------------
Disclaimer
--------------------------------------------------------------------------------
Thomson Reuters reserves the right to make changes to documents, content, or other 
information on this web site without obligation to notify any person of 
such changes.

In the conference calls upon which Event Transcripts are based, companies 
may make projections or other forward-looking statements regarding a variety 
of items. Such forward-looking statements are based upon current 
expectations and involve risks and uncertainties. Actual results may differ 
materially from those stated in any forward-looking statement based on a 
number of important factors and risks, which are more specifically 
identified in the companies' most recent SEC filings. Although the companies 
may indicate and believe that the assumptions underlying the forward-looking 
statements are reasonable, any of the assumptions could prove inaccurate or 
incorrect and, therefore, there can be no assurance that the results 
contemplated in the forward-looking statements will be realized.

THE INFORMATION CONTAINED IN EVENT TRANSCRIPTS IS A TEXTUAL REPRESENTATION
OF THE APPLICABLE COMPANY'S CONFERENCE CALL AND WHILE EFFORTS ARE MADE TO
PROVIDE AN ACCURATE TRANSCRIPTION, THERE MAY BE MATERIAL ERRORS, OMISSIONS,
OR INACCURACIES IN THE REPORTING OF THE SUBSTANCE OF THE CONFERENCE CALLS.
IN NO WAY DOES THOMSON REUTERS OR THE APPLICABLE COMPANY ASSUME ANY RESPONSIBILITY FOR ANY INVESTMENT OR OTHER
DECISIONS MADE BASED UPON THE INFORMATION PROVIDED ON THIS WEB SITE OR IN
ANY EVENT TRANSCRIPT. USERS ARE ADVISED TO REVIEW THE APPLICABLE COMPANY'S
CONFERENCE CALL ITSELF AND THE APPLICABLE COMPANY'S SEC FILINGS BEFORE
MAKING ANY INVESTMENT OR OTHER DECISIONS.
--------------------------------------------------------------------------------
Copyright 2019 Thomson Reuters. All Rights Reserved.
--------------------------------------------------------------------------------
